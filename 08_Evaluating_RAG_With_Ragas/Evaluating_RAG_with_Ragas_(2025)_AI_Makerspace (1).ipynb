{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"ab41e295a2c74bbea6f9ed623f80cccf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_dd7bfb01134b4065ba69d6da999a38b1","IPY_MODEL_2f5810ee1f3e4c5d9ee92b9d425cc9a1","IPY_MODEL_0cdd4cf8d0984dd6bb5cec714da6a496"],"layout":"IPY_MODEL_359cc6a3b0dd41e6bcd779ec3eb9105f"}},"dd7bfb01134b4065ba69d6da999a38b1":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfa5679aeeeb4fb9894d7914da689fda","placeholder":"​","style":"IPY_MODEL_2d3c38f320a84785a8637df51b8687a7","value":"Applying HeadlinesExtractor: 100%"}},"2f5810ee1f3e4c5d9ee92b9d425cc9a1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_e7f8602dbb8b4972a7f134dd0f545336","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a6f4743e01594db6a326a3e6acc78207","value":2}},"0cdd4cf8d0984dd6bb5cec714da6a496":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_10e87a53c74e4aa88b00c959d8591eff","placeholder":"​","style":"IPY_MODEL_8673cbe2976c48b4ae79ff3293adaa2a","value":" 2/2 [00:09&lt;00:00,  5.29s/it]"}},"359cc6a3b0dd41e6bcd779ec3eb9105f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"cfa5679aeeeb4fb9894d7914da689fda":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d3c38f320a84785a8637df51b8687a7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e7f8602dbb8b4972a7f134dd0f545336":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a6f4743e01594db6a326a3e6acc78207":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"10e87a53c74e4aa88b00c959d8591eff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8673cbe2976c48b4ae79ff3293adaa2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9a4aad37636c47159e4f26c6d72e3854":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5798e820df1a4324944e1cf34808a6b2","IPY_MODEL_eed729b2cff242a2a23b4ade77ddd848","IPY_MODEL_2d848c7bc72642e5a2756b96b215bda7"],"layout":"IPY_MODEL_fc286aabad314163b6e450be55162415"}},"5798e820df1a4324944e1cf34808a6b2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ae3d2f5bd97844dabdcc44f5858d6d26","placeholder":"​","style":"IPY_MODEL_543bc3c5d65448e288d38772576741fc","value":"Applying HeadlineSplitter:   0%"}},"eed729b2cff242a2a23b4ade77ddd848":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_d50eeebe44ee4f4495f3c918255fe0a1","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_0e88d04d06104846a59d4d31c33f6817","value":2}},"2d848c7bc72642e5a2756b96b215bda7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_83ef780d646e475ca8bbbe6046455785","placeholder":"​","style":"IPY_MODEL_d251aefb5336480bb221a09a9eaa692a","value":" 0/2 [00:00&lt;?, ?it/s]"}},"fc286aabad314163b6e450be55162415":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"ae3d2f5bd97844dabdcc44f5858d6d26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"543bc3c5d65448e288d38772576741fc":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d50eeebe44ee4f4495f3c918255fe0a1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0e88d04d06104846a59d4d31c33f6817":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"83ef780d646e475ca8bbbe6046455785":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d251aefb5336480bb221a09a9eaa692a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"924ccf4ba6084adfbaba61048b21253f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_69a0ae5f58434374bd2a3dbabce57f50","IPY_MODEL_53e1401eddc5436297bfeacd48d7f79a","IPY_MODEL_1f1329536889482181c30de6b5ea9b33"],"layout":"IPY_MODEL_176c4e97022c4ab99226354c2363aa06"}},"69a0ae5f58434374bd2a3dbabce57f50":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f727c7b3328410aab2397bca725c82e","placeholder":"​","style":"IPY_MODEL_09b472a28de84d10ab8cae6b0f723998","value":"Applying SummaryExtractor: 100%"}},"53e1401eddc5436297bfeacd48d7f79a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e7fbaf99c2a4e84a6352f95cd2956b9","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dc657dd24ac24f0b9c437e05982c0dbd","value":2}},"1f1329536889482181c30de6b5ea9b33":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b0a4b5d954cc4c928a0f7bb66d959514","placeholder":"​","style":"IPY_MODEL_de9287d81e6f41f6b1c5439f8554e15f","value":" 2/2 [00:03&lt;00:00,  1.45s/it]"}},"176c4e97022c4ab99226354c2363aa06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"5f727c7b3328410aab2397bca725c82e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"09b472a28de84d10ab8cae6b0f723998":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8e7fbaf99c2a4e84a6352f95cd2956b9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dc657dd24ac24f0b9c437e05982c0dbd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b0a4b5d954cc4c928a0f7bb66d959514":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de9287d81e6f41f6b1c5439f8554e15f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8cfe14cb55214699a8842fe507af7eaf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6550f906ffe847fca3a0f2929bdbd329","IPY_MODEL_b37f04943e444c96bcc0baaee45c292a","IPY_MODEL_8fa6784f6c8e45778eef839c1324b4fc"],"layout":"IPY_MODEL_82aa5c458ab3415880d9358e4362bbde"}},"6550f906ffe847fca3a0f2929bdbd329":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_09d9b82e39694c5a824db6fbc774492e","placeholder":"​","style":"IPY_MODEL_9bb0e5f4c4ba46408a54d2cf1d01ae79","value":"Applying CustomNodeFilter: 100%"}},"b37f04943e444c96bcc0baaee45c292a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_86abc97b88e5413285a2c05fe2fb0cd7","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b5144bb525e14f53ac142c87cea60abc","value":12}},"8fa6784f6c8e45778eef839c1324b4fc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5d02e2cfec44ad9ada2a0adcf4eebd6","placeholder":"​","style":"IPY_MODEL_d8fdbdf3af6349ca9a3a9da0d7a2108a","value":" 12/12 [00:26&lt;00:00,  3.24s/it]"}},"82aa5c458ab3415880d9358e4362bbde":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"09d9b82e39694c5a824db6fbc774492e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9bb0e5f4c4ba46408a54d2cf1d01ae79":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"86abc97b88e5413285a2c05fe2fb0cd7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5144bb525e14f53ac142c87cea60abc":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"b5d02e2cfec44ad9ada2a0adcf4eebd6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8fdbdf3af6349ca9a3a9da0d7a2108a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c52a0db35e6f474ba1f1d8b9b04d62bd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_18506f4e2e714cdfad0ac477f074e758","IPY_MODEL_1b00b665864648c684c1364d91545964","IPY_MODEL_9c7d68dccb904d848e07300b0135c5f7"],"layout":"IPY_MODEL_25353d484e31485890be762b7b47578c"}},"18506f4e2e714cdfad0ac477f074e758":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1ee892c952c147758c6af40ca6d2d37d","placeholder":"​","style":"IPY_MODEL_426845e452b14ef7b97e04de86f33b84","value":"Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]: 100%"}},"1b00b665864648c684c1364d91545964":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_a87ccc40bc28468faed69dfe8b2b88e5","max":26,"min":0,"orientation":"horizontal","style":"IPY_MODEL_804bb843a7dc42d886deceaa0f2884f9","value":26}},"9c7d68dccb904d848e07300b0135c5f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33af317713a944229be381230c4a9d27","placeholder":"​","style":"IPY_MODEL_210862abb408498bbdf759608c1321d1","value":" 26/26 [01:19&lt;00:00,  5.29s/it]"}},"25353d484e31485890be762b7b47578c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"1ee892c952c147758c6af40ca6d2d37d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"426845e452b14ef7b97e04de86f33b84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a87ccc40bc28468faed69dfe8b2b88e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"804bb843a7dc42d886deceaa0f2884f9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33af317713a944229be381230c4a9d27":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"210862abb408498bbdf759608c1321d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43be9fb878434e7aba129ca97dcbe4c2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_877328d861e04e73bda1bf0889fe2d1e","IPY_MODEL_b49d33622fa54915a9ee01a11828253d","IPY_MODEL_91517c6cb9004408879686ab592e48f2"],"layout":"IPY_MODEL_aa183ad4198f4177b4288d1afe5fd69f"}},"877328d861e04e73bda1bf0889fe2d1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dcb8e5df0f724e27a6f3867dc46119b3","placeholder":"​","style":"IPY_MODEL_9601dce7efd247a5ab08cc57e1e66c5b","value":"Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%"}},"b49d33622fa54915a9ee01a11828253d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_b36dd5a8eb4f4063b5d84e5acd5c7b26","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c7024bb25ed844fdaf505b7aaf8bb494","value":2}},"91517c6cb9004408879686ab592e48f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad9b9065c6b74d3e83514e39adcb7a00","placeholder":"​","style":"IPY_MODEL_930edc8e46d04bc3b7e7dfbb17e6c710","value":" 0/2 [00:00&lt;?, ?it/s]"}},"aa183ad4198f4177b4288d1afe5fd69f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"dcb8e5df0f724e27a6f3867dc46119b3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9601dce7efd247a5ab08cc57e1e66c5b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b36dd5a8eb4f4063b5d84e5acd5c7b26":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c7024bb25ed844fdaf505b7aaf8bb494":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad9b9065c6b74d3e83514e39adcb7a00":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"930edc8e46d04bc3b7e7dfbb17e6c710":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"026133a3067d412c8983380cd497712a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9c8b0e5c2f4b47d1bb64207232cd3de4","IPY_MODEL_616fc806fe6e47069a90489f4c4bd7fd","IPY_MODEL_83c7861136da4727bdcf17a8357bed76"],"layout":"IPY_MODEL_c9e9bae4ac1d426f8b890d000cf3dd71"}},"9c8b0e5c2f4b47d1bb64207232cd3de4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3e4325036e26436f853bb19bc9a17350","placeholder":"​","style":"IPY_MODEL_639168cd085e48bbb80940f56963e372","value":"Generating personas: 100%"}},"616fc806fe6e47069a90489f4c4bd7fd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ddf9c0a5e03492390a1189310bb8843","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e9982ab6101341c88677f4ba16e6865d","value":2}},"83c7861136da4727bdcf17a8357bed76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d3c1c35a4304ccf94ac8c2b2e18e98f","placeholder":"​","style":"IPY_MODEL_b59f9b8f17494b088859cf4cdae67d01","value":" 2/2 [00:01&lt;00:00,  1.28it/s]"}},"c9e9bae4ac1d426f8b890d000cf3dd71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3e4325036e26436f853bb19bc9a17350":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"639168cd085e48bbb80940f56963e372":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ddf9c0a5e03492390a1189310bb8843":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9982ab6101341c88677f4ba16e6865d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d3c1c35a4304ccf94ac8c2b2e18e98f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b59f9b8f17494b088859cf4cdae67d01":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"89aaf581f8ae4d84baf228bf05a8abdf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_73292ad6e34140faa313e343cd6afbcc","IPY_MODEL_2dad0574245c4c2b8abd6bdf96cf6321","IPY_MODEL_63cae94fae1f413cb7cfe5fc3fe910b3"],"layout":"IPY_MODEL_09c9052972c747c1a910d1ab57ec5db6"}},"73292ad6e34140faa313e343cd6afbcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c4b73aee575e4432b9ec3148f4e32af5","placeholder":"​","style":"IPY_MODEL_5283d4d52afa4df6989c9f8a178a6b29","value":"Generating Scenarios: 100%"}},"2dad0574245c4c2b8abd6bdf96cf6321":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5cc59944b9c543db9d869a6e66a14a47","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_baf8c53543fb4b02a75c66714804b314","value":3}},"63cae94fae1f413cb7cfe5fc3fe910b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0a3bb37b1c4b44d9853aaae13dc6a5d1","placeholder":"​","style":"IPY_MODEL_c1e3570a83564e0f8a1b18fc3eaa674c","value":" 3/3 [00:06&lt;00:00,  1.91s/it]"}},"09c9052972c747c1a910d1ab57ec5db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c4b73aee575e4432b9ec3148f4e32af5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5283d4d52afa4df6989c9f8a178a6b29":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5cc59944b9c543db9d869a6e66a14a47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baf8c53543fb4b02a75c66714804b314":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0a3bb37b1c4b44d9853aaae13dc6a5d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c1e3570a83564e0f8a1b18fc3eaa674c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"852ccf11e61e4565b5657cb6c8c1676c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cac7db0bcf3948deb01b0e32e0427caf","IPY_MODEL_6a336a9afe164b4f8a209de0bd987821","IPY_MODEL_b2a1b23fa2fa43a08c11b266850d9810"],"layout":"IPY_MODEL_5a67af84274e4f3e8774d4753b1a6abd"}},"cac7db0bcf3948deb01b0e32e0427caf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e9b2beda648e4bcc922828a26bc567e5","placeholder":"​","style":"IPY_MODEL_604eecbee4554c3785f2dbc8d417c006","value":"Generating Samples: 100%"}},"6a336a9afe164b4f8a209de0bd987821":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_07d27f7378c94d22a4b166ef5e9315a5","max":12,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5c6b23b2e8734e3a90e645f82ddaf044","value":12}},"b2a1b23fa2fa43a08c11b266850d9810":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fcc2ca9cfbca4c59b1d5ea6e9d6f5d0c","placeholder":"​","style":"IPY_MODEL_28c9721a4ece4c939ebd7457c839fcf9","value":" 12/12 [01:07&lt;00:00,  8.09s/it]"}},"5a67af84274e4f3e8774d4753b1a6abd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b2beda648e4bcc922828a26bc567e5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"604eecbee4554c3785f2dbc8d417c006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"07d27f7378c94d22a4b166ef5e9315a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c6b23b2e8734e3a90e645f82ddaf044":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fcc2ca9cfbca4c59b1d5ea6e9d6f5d0c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28c9721a4ece4c939ebd7457c839fcf9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f22d837877fe44178f064641c873d053":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_78719c3074564b609574a67f61a3d771","IPY_MODEL_a3b07ef88ed24d37b0e0601a0f81408a","IPY_MODEL_8c31e1565f204652950556a6916dea4d"],"layout":"IPY_MODEL_01eddca9b41e46f2b790788fb50d1a08"}},"78719c3074564b609574a67f61a3d771":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfff5091b6fe41a38ec7ee22acfc71e0","placeholder":"​","style":"IPY_MODEL_40ff01bb41ad4d81a3d579dcbc2c923b","value":"Evaluating: 100%"}},"a3b07ef88ed24d37b0e0601a0f81408a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ac19798d07c7444b8e2e8d2edb45f3cd","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a6c05e7d7d74f369f79771e4ff0b741","value":72}},"8c31e1565f204652950556a6916dea4d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a661d000cbe743378d0c813b4cbe7d3f","placeholder":"​","style":"IPY_MODEL_6e649fb90af940f0bdc255e1f5fa95a3","value":" 72/72 [09:48&lt;00:00, 18.02s/it]"}},"01eddca9b41e46f2b790788fb50d1a08":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfff5091b6fe41a38ec7ee22acfc71e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40ff01bb41ad4d81a3d579dcbc2c923b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ac19798d07c7444b8e2e8d2edb45f3cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a6c05e7d7d74f369f79771e4ff0b741":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a661d000cbe743378d0c813b4cbe7d3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e649fb90af940f0bdc255e1f5fa95a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c13e5b8733e84c4bb9d3b3863dcfd2e5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b00b3083c45a46d09d0a94ff18111028","IPY_MODEL_1cf0cbb87244493bbe7bc15b8b6b9a7e","IPY_MODEL_a0ba007a755a4ef8a766074ffef6b9fa"],"layout":"IPY_MODEL_3d7e5e39830f4542af08458bb6f24693"}},"b00b3083c45a46d09d0a94ff18111028":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0ade375a9cdf43a0a092042917ce1130","placeholder":"​","style":"IPY_MODEL_5969d04d247c4ae58b58ef13381aa312","value":"Evaluating: 100%"}},"1cf0cbb87244493bbe7bc15b8b6b9a7e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f35c92e09eb543d9aa6f933d00092d8b","max":72,"min":0,"orientation":"horizontal","style":"IPY_MODEL_35a7936a421c4165b0bfdfbbe809d498","value":72}},"a0ba007a755a4ef8a766074ffef6b9fa":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0811a7e3d96a43b4bba083483f8fa29a","placeholder":"​","style":"IPY_MODEL_597b05f5120d46d1a9c213793a1d2767","value":" 72/72 [10:17&lt;00:00, 26.26s/it]"}},"3d7e5e39830f4542af08458bb6f24693":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0ade375a9cdf43a0a092042917ce1130":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5969d04d247c4ae58b58ef13381aa312":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f35c92e09eb543d9aa6f933d00092d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"35a7936a421c4165b0bfdfbbe809d498":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"0811a7e3d96a43b4bba083483f8fa29a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"597b05f5120d46d1a9c213793a1d2767":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# Using Ragas to Evaluate a RAG Application built with LangChain and LangGraph\n","\n","In the following notebook, we'll be looking at how [Ragas](https://github.com/explodinggradients/ragas) can be helpful in a number of ways when looking to evaluate your RAG applications!\n","\n","While this example is rooted in LangChain/LangGraph - Ragas is framework agnostic (you don't even need to be using a framework!).\n","\n","- 🤝 Breakout Room #1\n","  1. Task 1: Installing Required Libraries\n","  2. Task 2: Set Environment Variables\n","  3. Task 3: Synthetic Dataset Generation for Evaluation using Ragas (Optional)\n","\n","- 🤝 Breakout Room #2\n","  1. Task 4: Evaluating our Pipeline with Ragas\n","  2. Task 5: Testing OpenAI's Claim\n","  3. Task 6: Selecting an Advanced Retriever and Evaluating\n","\n","But first! Let's set some dependencies!"],"metadata":{"id":"iLokDKoN1aKv"}},{"cell_type":"markdown","source":["## Dependencies and API Keys:"],"metadata":{"id":"0k9tqHdq2BGi"}},{"cell_type":"code","source":["!pip install -qU ragas==0.2.10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"njvrpsHWifeS","outputId":"c2f748f6-efb0-494e-ad11-c1b31d57dc92","executionInfo":{"status":"ok","timestamp":1738859012917,"user_tz":360,"elapsed":28026,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/175.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m174.1/175.7 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.7/175.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/45.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.1/71.1 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m412.7/412.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n","torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n","gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install -qU langchain-community==0.3.14 langchain-openai==0.2.14 unstructured==0.16.12 langgraph==0.2.61 langchain-qdrant==0.2.0"],"metadata":{"id":"DjesmARj2I4A","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1738859052492,"user_tz":360,"elapsed":39579,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}},"outputId":"15e3ae28-0a6b-4dba-c87c-8453e8bd1e7a"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m890.9/981.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m55.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.2/137.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m326.9/326.9 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m306.6/306.6 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.8/166.8 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m67.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.7/298.7 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"markdown","source":["We'll also need to provide our API keys.\n","\n","First, OpenAI's for our LLM/embedding model combination!"],"metadata":{"id":"H3d5seTX2xyx"}},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_J02wP3gdLds","outputId":"58fd9960-3a9b-4b8f-d27a-584fe5bde2b4","executionInfo":{"status":"ok","timestamp":1738859055565,"user_tz":360,"elapsed":3104,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter your OpenAI API key!··········\n"]}],"source":["import os\n","from getpass import getpass\n","os.environ[\"OPENAI_API_KEY\"] = getpass(\"Please enter your OpenAI API key!\")"]},{"cell_type":"markdown","source":["OPTIONALLY:\n","\n","We can also provide a Ragas API key - which you can sign-up for [here](https://app.ragas.io/)."],"metadata":{"id":"eU9cDbFa23oP"}},{"cell_type":"code","source":["os.environ[\"RAGAS_APP_TOKEN\"] = getpass(\"Please enter your Ragas API key!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1dInPQkxfUhg","outputId":"ca6ccb75-5175-486c-c978-03cad607ab3d","executionInfo":{"status":"ok","timestamp":1738859143812,"user_tz":360,"elapsed":2287,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":4,"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter your Ragas API key!··········\n"]}]},{"cell_type":"markdown","source":["## Generating Synthetic Test Data\n","\n","We wil be using Ragas to build out a set of synthetic test questions, references, and reference contexts. This is useful because it will allow us to find out how our system is performing.\n","\n","> NOTE: Ragas is best suited for finding *directional* changes in your LLM-based systems. The absolute scores aren't comparable in a vacuum."],"metadata":{"id":"_zTz1-4U3Hg0"}},{"cell_type":"markdown","source":["### Data Preparation\n","\n","We'll prepare our data - and download our webpages which we'll be using for our data today.\n","\n","These webpages are from [Simon Willison's](https://simonwillison.net/) yearly \"AI learnings\".\n","\n","- [2023 Blog](https://simonwillison.net/2023/Dec/31/ai-in-2023/)\n","- [2024 Blog](https://simonwillison.net/2024/Dec/31/llms-in-2024/)\n","\n","Let's start by collecting our data into a useful pile!"],"metadata":{"id":"pssK40Eh4MIc"}},{"cell_type":"code","source":["!mkdir data"],"metadata":{"id":"12cpcowvhW3O","executionInfo":{"status":"ok","timestamp":1738859146334,"user_tz":360,"elapsed":281,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["!curl https://simonwillison.net/2023/Dec/31/ai-in-2023/ -o data/2023_llms.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XAHtGwnsfiA5","outputId":"834b85f9-1f9c-4a78-eb38-de43937380cb","executionInfo":{"status":"ok","timestamp":1738859148369,"user_tz":360,"elapsed":1277,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 31287    0 31287    0     0  34833      0 --:--:-- --:--:-- --:--:-- 34802\n"]}]},{"cell_type":"code","source":["!curl https://simonwillison.net/2024/Dec/31/llms-in-2024/ -o data/2024_llms.html"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pEs60mX1hB_a","outputId":"3e90650e-0d0e-47d2-833d-d7207d75ef1b","executionInfo":{"status":"ok","timestamp":1738859149548,"user_tz":360,"elapsed":1181,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n","                                 Dload  Upload   Total   Spent    Left  Speed\n","100 70146    0 70146    0     0  74935      0 --:--:-- --:--:-- --:--:-- 74862\n"]}]},{"cell_type":"markdown","source":["Next, let's load our data into a familiar LangChain format using the `DirectoryLoader`."],"metadata":{"id":"SfKQgiR14Omj"}},{"cell_type":"code","source":["from langchain_community.document_loaders import DirectoryLoader\n","\n","path = \"data/\"\n","loader = DirectoryLoader(path, glob=\"*.html\")\n","docs = loader.load()"],"metadata":{"id":"dTYMPlsTiDRe","executionInfo":{"status":"ok","timestamp":1738859159432,"user_tz":360,"elapsed":9887,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["### Knowledge Graph Based Synthetic Generation\n","\n","Ragas uses a knowledge graph based approach to create data. This is extremely useful as it allows us to create complex queries rather simply. The additional testset complexity allows us to evaluate larger problems more effectively, as systems tend to be very strong on simple evaluation tasks.\n","\n","Let's start by defining our `generator_llm` (which will generate our questions, summaries, and more), and our `generator_embeddings` which will be useful in building our graph."],"metadata":{"id":"lfyA65MM4Tbn"}},{"cell_type":"code","source":["from ragas.llms import LangchainLLMWrapper\n","from ragas.embeddings import LangchainEmbeddingsWrapper\n","from langchain_openai import ChatOpenAI\n","from langchain_openai import OpenAIEmbeddings\n","generator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))\n","generator_embeddings = LangchainEmbeddingsWrapper(OpenAIEmbeddings())"],"metadata":{"id":"m2_fhP3FFqHs","executionInfo":{"status":"ok","timestamp":1738859262245,"user_tz":360,"elapsed":1530,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["### Abstracted SDG\n","\n","The above method is the full process - but we can shortcut that using the provided abstractions!\n","\n","This will generate our knowledge graph under the hood, and will - from there - generate our personas and scenarios to construct our queries.\n","\n"],"metadata":{"id":"qbZ9j1EL-X55"}},{"cell_type":"code","source":["from ragas.testset import TestsetGenerator\n","\n","generator = TestsetGenerator(llm=generator_llm, embedding_model=generator_embeddings)\n","dataset = generator.generate_with_langchain_docs(docs, testset_size=10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["ab41e295a2c74bbea6f9ed623f80cccf","dd7bfb01134b4065ba69d6da999a38b1","2f5810ee1f3e4c5d9ee92b9d425cc9a1","0cdd4cf8d0984dd6bb5cec714da6a496","359cc6a3b0dd41e6bcd779ec3eb9105f","cfa5679aeeeb4fb9894d7914da689fda","2d3c38f320a84785a8637df51b8687a7","e7f8602dbb8b4972a7f134dd0f545336","a6f4743e01594db6a326a3e6acc78207","10e87a53c74e4aa88b00c959d8591eff","8673cbe2976c48b4ae79ff3293adaa2a","9a4aad37636c47159e4f26c6d72e3854","5798e820df1a4324944e1cf34808a6b2","eed729b2cff242a2a23b4ade77ddd848","2d848c7bc72642e5a2756b96b215bda7","fc286aabad314163b6e450be55162415","ae3d2f5bd97844dabdcc44f5858d6d26","543bc3c5d65448e288d38772576741fc","d50eeebe44ee4f4495f3c918255fe0a1","0e88d04d06104846a59d4d31c33f6817","83ef780d646e475ca8bbbe6046455785","d251aefb5336480bb221a09a9eaa692a","924ccf4ba6084adfbaba61048b21253f","69a0ae5f58434374bd2a3dbabce57f50","53e1401eddc5436297bfeacd48d7f79a","1f1329536889482181c30de6b5ea9b33","176c4e97022c4ab99226354c2363aa06","5f727c7b3328410aab2397bca725c82e","09b472a28de84d10ab8cae6b0f723998","8e7fbaf99c2a4e84a6352f95cd2956b9","dc657dd24ac24f0b9c437e05982c0dbd","b0a4b5d954cc4c928a0f7bb66d959514","de9287d81e6f41f6b1c5439f8554e15f","8cfe14cb55214699a8842fe507af7eaf","6550f906ffe847fca3a0f2929bdbd329","b37f04943e444c96bcc0baaee45c292a","8fa6784f6c8e45778eef839c1324b4fc","82aa5c458ab3415880d9358e4362bbde","09d9b82e39694c5a824db6fbc774492e","9bb0e5f4c4ba46408a54d2cf1d01ae79","86abc97b88e5413285a2c05fe2fb0cd7","b5144bb525e14f53ac142c87cea60abc","b5d02e2cfec44ad9ada2a0adcf4eebd6","d8fdbdf3af6349ca9a3a9da0d7a2108a","c52a0db35e6f474ba1f1d8b9b04d62bd","18506f4e2e714cdfad0ac477f074e758","1b00b665864648c684c1364d91545964","9c7d68dccb904d848e07300b0135c5f7","25353d484e31485890be762b7b47578c","1ee892c952c147758c6af40ca6d2d37d","426845e452b14ef7b97e04de86f33b84","a87ccc40bc28468faed69dfe8b2b88e5","804bb843a7dc42d886deceaa0f2884f9","33af317713a944229be381230c4a9d27","210862abb408498bbdf759608c1321d1","43be9fb878434e7aba129ca97dcbe4c2","877328d861e04e73bda1bf0889fe2d1e","b49d33622fa54915a9ee01a11828253d","91517c6cb9004408879686ab592e48f2","aa183ad4198f4177b4288d1afe5fd69f","dcb8e5df0f724e27a6f3867dc46119b3","9601dce7efd247a5ab08cc57e1e66c5b","b36dd5a8eb4f4063b5d84e5acd5c7b26","c7024bb25ed844fdaf505b7aaf8bb494","ad9b9065c6b74d3e83514e39adcb7a00","930edc8e46d04bc3b7e7dfbb17e6c710","026133a3067d412c8983380cd497712a","9c8b0e5c2f4b47d1bb64207232cd3de4","616fc806fe6e47069a90489f4c4bd7fd","83c7861136da4727bdcf17a8357bed76","c9e9bae4ac1d426f8b890d000cf3dd71","3e4325036e26436f853bb19bc9a17350","639168cd085e48bbb80940f56963e372","7ddf9c0a5e03492390a1189310bb8843","e9982ab6101341c88677f4ba16e6865d","1d3c1c35a4304ccf94ac8c2b2e18e98f","b59f9b8f17494b088859cf4cdae67d01","89aaf581f8ae4d84baf228bf05a8abdf","73292ad6e34140faa313e343cd6afbcc","2dad0574245c4c2b8abd6bdf96cf6321","63cae94fae1f413cb7cfe5fc3fe910b3","09c9052972c747c1a910d1ab57ec5db6","c4b73aee575e4432b9ec3148f4e32af5","5283d4d52afa4df6989c9f8a178a6b29","5cc59944b9c543db9d869a6e66a14a47","baf8c53543fb4b02a75c66714804b314","0a3bb37b1c4b44d9853aaae13dc6a5d1","c1e3570a83564e0f8a1b18fc3eaa674c","852ccf11e61e4565b5657cb6c8c1676c","cac7db0bcf3948deb01b0e32e0427caf","6a336a9afe164b4f8a209de0bd987821","b2a1b23fa2fa43a08c11b266850d9810","5a67af84274e4f3e8774d4753b1a6abd","e9b2beda648e4bcc922828a26bc567e5","604eecbee4554c3785f2dbc8d417c006","07d27f7378c94d22a4b166ef5e9315a5","5c6b23b2e8734e3a90e645f82ddaf044","fcc2ca9cfbca4c59b1d5ea6e9d6f5d0c","28c9721a4ece4c939ebd7457c839fcf9"]},"id":"ZvXsRbwIlfm1","outputId":"b5060a95-ebe2-4a5c-a191-29e0f1903d99","executionInfo":{"status":"ok","timestamp":1738859463103,"user_tz":360,"elapsed":198223,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":11,"outputs":[{"output_type":"display_data","data":{"text/plain":["Applying HeadlinesExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab41e295a2c74bbea6f9ed623f80cccf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying HeadlineSplitter:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9a4aad37636c47159e4f26c6d72e3854"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying SummaryExtractor:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"924ccf4ba6084adfbaba61048b21253f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying CustomNodeFilter:   0%|          | 0/12 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8cfe14cb55214699a8842fe507af7eaf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying [EmbeddingExtractor, ThemesExtractor, NERExtractor]:   0%|          | 0/26 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c52a0db35e6f474ba1f1d8b9b04d62bd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Applying [CosineSimilarityBuilder, OverlapScoreBuilder]:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43be9fb878434e7aba129ca97dcbe4c2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating personas:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026133a3067d412c8983380cd497712a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating Scenarios:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89aaf581f8ae4d84baf228bf05a8abdf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Generating Samples:   0%|          | 0/12 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"852ccf11e61e4565b5657cb6c8c1676c"}},"metadata":{}}]},{"cell_type":"code","source":["dataset.to_pandas()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"id":"1jsrtjNllwiI","outputId":"68c3e24f-9a22-4c67-8307-e9448f54a3c7","executionInfo":{"status":"ok","timestamp":1738859540958,"user_tz":360,"elapsed":238,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           user_input  \\\n","0                 Wht did we lern about LLMs in 2024?   \n","1   How do LLMs handle the complexity of Chinese g...   \n","2       What were the key developments in AI in 2023?   \n","3       What plausible impact AI models have on jobs?   \n","4   How have advancements in model efficiency and ...   \n","5   How has the universal access to AI models evol...   \n","6   How have advancements in model efficiency and ...   \n","7   How has universal access to AI models and API ...   \n","8   What were the significant advancements in Larg...   \n","9   How has the development of Claude 3 and the ri...   \n","10  What advancements in Large Language Models (LL...   \n","11  How has Anthropic's approach to model evaluati...   \n","\n","                                   reference_contexts  \\\n","0   [Code may be the best application The ethics o...   \n","1   [Based Development As a computer scientist and...   \n","2   [Simon Willison’s Weblog Subscribe Stuff we fi...   \n","3   [easy to follow. The rest of the document incl...   \n","4   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","5   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","6   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","7   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","8   [<1-hop>\\n\\nSimon Willison’s Weblog Subscribe ...   \n","9   [<1-hop>\\n\\nI’m beginning to see the most popu...   \n","10  [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","11  [<1-hop>\\n\\nI’m beginning to see the most popu...   \n","\n","                                            reference  \\\n","0   The most surprising thing we’ve learned about ...   \n","1   The grammar rules of programming languages lik...   \n","2   2023 was the breakthrough year for Large Langu...   \n","3   People have certainly lost work to AI models—a...   \n","4   Advancements in model efficiency and pricing h...   \n","5   Universal access to the best AI models was bri...   \n","6   Advancements in model efficiency and pricing h...   \n","7   Universal access to AI models experienced a br...   \n","8   In 2024, significant advancements in Large Lan...   \n","9   The development of Claude 3 and the rise of in...   \n","10  In 2023, significant advancements in Large Lan...   \n","11  Anthropic's approach to model evaluation, as h...   \n","\n","                        synthesizer_name  \n","0   single_hop_specifc_query_synthesizer  \n","1   single_hop_specifc_query_synthesizer  \n","2   single_hop_specifc_query_synthesizer  \n","3   single_hop_specifc_query_synthesizer  \n","4   multi_hop_abstract_query_synthesizer  \n","5   multi_hop_abstract_query_synthesizer  \n","6   multi_hop_abstract_query_synthesizer  \n","7   multi_hop_abstract_query_synthesizer  \n","8   multi_hop_specific_query_synthesizer  \n","9   multi_hop_specific_query_synthesizer  \n","10  multi_hop_specific_query_synthesizer  \n","11  multi_hop_specific_query_synthesizer  "],"text/html":["\n","  <div id=\"df-06fb1817-08aa-49f6-a5c1-c4a8572e0303\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_input</th>\n","      <th>reference_contexts</th>\n","      <th>reference</th>\n","      <th>synthesizer_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Wht did we lern about LLMs in 2024?</td>\n","      <td>[Code may be the best application The ethics o...</td>\n","      <td>The most surprising thing we’ve learned about ...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How do LLMs handle the complexity of Chinese g...</td>\n","      <td>[Based Development As a computer scientist and...</td>\n","      <td>The grammar rules of programming languages lik...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What were the key developments in AI in 2023?</td>\n","      <td>[Simon Willison’s Weblog Subscribe Stuff we fi...</td>\n","      <td>2023 was the breakthrough year for Large Langu...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What plausible impact AI models have on jobs?</td>\n","      <td>[easy to follow. The rest of the document incl...</td>\n","      <td>People have certainly lost work to AI models—a...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How have advancements in model efficiency and ...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>Advancements in model efficiency and pricing h...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>How has the universal access to AI models evol...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>Universal access to the best AI models was bri...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>How have advancements in model efficiency and ...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>Advancements in model efficiency and pricing h...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>How has universal access to AI models and API ...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>Universal access to AI models experienced a br...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>What were the significant advancements in Larg...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nSimon Willison’s Weblog Subscribe ...</td>\n","      <td>In 2024, significant advancements in Large Lan...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>How has the development of Claude 3 and the ri...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nI’m beginning to see the most popu...</td>\n","      <td>The development of Claude 3 and the rise of in...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>What advancements in Large Language Models (LL...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>In 2023, significant advancements in Large Lan...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>How has Anthropic's approach to model evaluati...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nI’m beginning to see the most popu...</td>\n","      <td>Anthropic's approach to model evaluation, as h...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06fb1817-08aa-49f6-a5c1-c4a8572e0303')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-06fb1817-08aa-49f6-a5c1-c4a8572e0303 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-06fb1817-08aa-49f6-a5c1-c4a8572e0303');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-b342b921-983f-42eb-9efd-841dee5360b5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b342b921-983f-42eb-9efd-841dee5360b5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-b342b921-983f-42eb-9efd-841dee5360b5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"dataset\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"What advancements in Large Language Models (LLMs) were highlighted in 2023, and how did they impact the capabilities of models like GPT-4?\",\n          \"How has the development of Claude 3 and the rise of inference-scaling reasoning models influenced the efficiency and capabilities of large language models in 2024?\",\n          \"Wht did we lern about LLMs in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"In 2023, significant advancements in Large Language Models (LLMs) were observed, marking it as a breakthrough year for AI. One of the key developments was the ability to run LLMs on personal devices, which was previously thought to require datacenter-class servers. This was exemplified by models like Qwen2.5-Coder-32B and Meta's Llama 3.3 70B, which could run on a 64GB M2 MacBook Pro. Additionally, the cost of running prompts through top-tier hosted LLMs dramatically decreased, making these models more accessible. The year also saw the emergence of models that surpassed GPT-4 in performance, with 18 organizations having models ranked higher than GPT-4-0314 on the Chatbot Arena Leaderboard. These advancements not only improved model efficiency but also expanded the capabilities of LLMs, allowing for longer input contexts and new functionalities such as video input, as seen with Google's Gemini 1.5 Pro.\",\n          \"The development of Claude 3 and the rise of inference-scaling reasoning models have significantly influenced the efficiency and capabilities of large language models in 2024. Claude 3, launched by Anthropic, became a favorite due to its enhanced capabilities, and its subsequent upgrade to Claude 3.5 Sonnet further solidified its position. This model, along with others, contributed to breaking the GPT-4 barrier, as evidenced by the fact that 18 organizations now have models ranking higher than the original GPT-4 on the Chatbot Arena Leaderboard. Additionally, the introduction of inference-scaling reasoning models, such as OpenAI's o1 and its successor o3, has opened new avenues for scaling models by allowing them to tackle harder problems through increased compute during inference rather than just during training. This has led to models that can handle more complex tasks and has driven down the cost of running prompts through top-tier hosted LLMs, making them more accessible and efficient.\",\n          \"The most surprising thing we\\u2019ve learned about LLMs this year is that they\\u2019re actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthesizer_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"single_hop_specifc_query_synthesizer\",\n          \"multi_hop_abstract_query_synthesizer\",\n          \"multi_hop_specific_query_synthesizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["#### OPTIONAL:\n","\n","If you've provided your Ragas API key - you can use this web interface to look at the created data!"],"metadata":{"id":"rFMVNyJn-7bT"}},{"cell_type":"code","source":["dataset.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":53},"id":"VEXOV88Vly5I","outputId":"ee10bb0b-bf52-4c58-f816-7710731bd6d8","executionInfo":{"status":"ok","timestamp":1738859548738,"user_tz":360,"elapsed":2337,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Testset uploaded! View at https://app.ragas.io/dashboard/alignment/testset/a2c7f697-fd3a-4abb-9643-d8f081e474b5\n"]},{"output_type":"execute_result","data":{"text/plain":["'https://app.ragas.io/dashboard/alignment/testset/a2c7f697-fd3a-4abb-9643-d8f081e474b5'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":13}]},{"cell_type":"markdown","source":["## LangChain RAG\n","\n","Now we'll construct our LangChain RAG, which we will be evaluating using the above created test data!"],"metadata":{"id":"Ni4Q14_arJYw"}},{"cell_type":"markdown","source":["### R - Retrieval\n","\n","Let's start with building our retrieval pipeline, which will involve loading the same data we used to create our synthetic test set above.\n","\n","> NOTE: We need to use the same data - as our test set is specifically designed for this data."],"metadata":{"id":"hGy99jkVrVqX"}},{"cell_type":"code","source":["path = \"data/\"\n","loader = DirectoryLoader(path, glob=\"*.html\")\n","docs = loader.load()"],"metadata":{"id":"847933Htono8","executionInfo":{"status":"ok","timestamp":1738859563615,"user_tz":360,"elapsed":473,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":["Now that we have our data loaded, let's split it into chunks!"],"metadata":{"id":"KQv3Psil_D2A"}},{"cell_type":"code","source":["from langchain.text_splitter import RecursiveCharacterTextSplitter\n","\n","text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n","split_documents = text_splitter.split_documents(docs)\n","len(split_documents)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2U0eJ_prZhL","outputId":"f030de79-981f-4bec-f3a7-ce921d01e273","executionInfo":{"status":"ok","timestamp":1738859565295,"user_tz":360,"elapsed":234,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["74"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["Next up, we'll need to provide an embedding model that we can use to construct our vector store."],"metadata":{"id":"2EcbmBBC_G2s"}},{"cell_type":"code","source":["from langchain_openai import OpenAIEmbeddings\n","\n","embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")"],"metadata":{"id":"KY_CNAbfr9sY","executionInfo":{"status":"ok","timestamp":1738859566502,"user_tz":360,"elapsed":220,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["Now we can build our in memory QDrant vector store."],"metadata":{"id":"AP_VDgyx_MPq"}},{"cell_type":"code","source":["from langchain_qdrant import QdrantVectorStore\n","from qdrant_client import QdrantClient\n","from qdrant_client.http.models import Distance, VectorParams\n","\n","client = QdrantClient(\":memory:\")\n","\n","client.create_collection(\n","    collection_name=\"ai_across_years\",\n","    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",")\n","\n","vector_store = QdrantVectorStore(\n","    client=client,\n","    collection_name=\"ai_across_years\",\n","    embedding=embeddings,\n",")"],"metadata":{"id":"AoxImnLJsC4Q","executionInfo":{"status":"ok","timestamp":1738859570556,"user_tz":360,"elapsed":2867,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["We can now add our documents to our vector store."],"metadata":{"id":"zUSCXe7x_h0O"}},{"cell_type":"code","source":["_ = vector_store.add_documents(documents=split_documents)"],"metadata":{"id":"Vckrosgpsfq2","executionInfo":{"status":"ok","timestamp":1738859576536,"user_tz":360,"elapsed":5982,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":["Let's define our retriever."],"metadata":{"id":"QBgsT5_m_lOD"}},{"cell_type":"code","source":["retriever = vector_store.as_retriever(search_kwargs={\"k\": 5})"],"metadata":{"id":"qmxRJeMbskTS","executionInfo":{"status":"ok","timestamp":1738859576536,"user_tz":360,"elapsed":10,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":["Now we can produce a node for retrieval!"],"metadata":{"id":"3ZX68nle_nUm"}},{"cell_type":"code","source":["def retrieve(state):\n","  retrieved_docs = retriever.invoke(state[\"question\"])\n","  return {\"context\" : retrieved_docs}"],"metadata":{"id":"RMuKChk8vmCv","executionInfo":{"status":"ok","timestamp":1738859576536,"user_tz":360,"elapsed":9,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["### Augmented\n","\n","Let's create a simple RAG prompt!"],"metadata":{"id":"48-mJHgUsvDG"}},{"cell_type":"code","source":["from langchain.prompts import ChatPromptTemplate\n","\n","RAG_PROMPT = \"\"\"\\\n","You are a helpful assistant who answers questions based on provided context. You must only use the provided context, and cannot use your own knowledge.\n","\n","### Question\n","{question}\n","\n","### Context\n","{context}\n","\"\"\"\n","\n","rag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT)"],"metadata":{"id":"C0masYYKsxLg","executionInfo":{"status":"ok","timestamp":1738859576537,"user_tz":360,"elapsed":9,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":["### Generation\n","\n","We'll also need an LLM to generate responses - we'll use `gpt-4o-mini` to avoid using the same model as our judge model."],"metadata":{"id":"cznU20c0uY9j"}},{"cell_type":"code","source":["from langchain_openai import ChatOpenAI\n","\n","llm = ChatOpenAI(model=\"gpt-4o-mini\")"],"metadata":{"id":"ZVHBcNGptdZt","executionInfo":{"status":"ok","timestamp":1738859576537,"user_tz":360,"elapsed":9,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Then we can create a `generate` node!"],"metadata":{"id":"YTpV7-b7_44n"}},{"cell_type":"code","source":["def generate(state):\n","  docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n","  messages = rag_prompt.format_messages(question=state[\"question\"], context=docs_content)\n","  response = llm.invoke(messages)\n","  return {\"response\" : response.content}"],"metadata":{"id":"trgefAs-wX84","executionInfo":{"status":"ok","timestamp":1738859576537,"user_tz":360,"elapsed":8,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":["### Building RAG Graph with LangGraph\n","\n","Let's create some state for our LangGraph RAG graph!"],"metadata":{"id":"hhD1IxvXu2zX"}},{"cell_type":"code","source":["from langgraph.graph import START, StateGraph\n","from typing_extensions import List, TypedDict\n","from langchain_core.documents import Document\n","\n","class State(TypedDict):\n","  question: str\n","  context: List[Document]\n","  response: str"],"metadata":{"id":"5-o5r2mqu8Og","executionInfo":{"status":"ok","timestamp":1738859576870,"user_tz":360,"elapsed":341,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Now we can build our simple graph!\n","\n","> NOTE: We're using `add_sequence` since we will always move from retrieval to generation. This is essentially building a chain in LangGraph."],"metadata":{"id":"DFEqEQje_--V"}},{"cell_type":"code","source":["graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n","graph_builder.add_edge(START, \"retrieve\")\n","graph = graph_builder.compile()"],"metadata":{"id":"8kMJ_bgWvU-q","executionInfo":{"status":"ok","timestamp":1738859576871,"user_tz":360,"elapsed":6,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":25,"outputs":[]},{"cell_type":"markdown","source":["Let's do a test to make sure it's doing what we'd expect."],"metadata":{"id":"dKX8yupqAIeQ"}},{"cell_type":"code","source":["response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})"],"metadata":{"id":"PXdB5pdbwzIF","executionInfo":{"status":"ok","timestamp":1738859587743,"user_tz":360,"elapsed":10877,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["response[\"response\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":143},"id":"JPuemnQQw5Y2","outputId":"1244282d-d5e2-48fa-fa16-78f12f0d2fdd","executionInfo":{"status":"ok","timestamp":1738859587743,"user_tz":360,"elapsed":23,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"LLM agents are useful for several reasons:\\n\\n1. **Ease of Building**: Creating LLMs has become relatively straightforward, requiring only a few hundred lines of Python code, as opposed to millions of lines of complex code that one might expect for such powerful systems. This accessibility means that more individuals and organizations can experiment with and deploy LLMs.\\n\\n2. **Data-Driven Performance**: The effectiveness of LLMs largely depends on the quality and quantity of the training data. If one can gather the right data and afford the necessary computational resources, building an effective LLM is achievable.\\n\\n3. **Running Locally**: Recent advancements, such as the release of models like Meta's Llama, have enabled users to run LLMs on their own devices. This democratizes access to LLM technology, allowing individuals to utilize these models without needing expensive servers.\\n\\n4. **Code Generation**: LLMs have proven particularly effective at generating code. They can produce code that can be executed and tested for correctness, significantly reducing the impact of hallucinations (i.e., generating incorrect or non-existent code). This capability makes them valuable tools for software engineering.\\n\\n5. **Automation and Assistance**: There is potential for LLMs to act as AI agents that can perform tasks on behalf of users. While practical applications are still developing, the concept of AI systems that can autonomously assist or act in various contexts is an exciting prospect.\\n\\nOverall, while LLMs warrant criticism for various reasons, including ethical concerns and environmental impact, their capacity for code generation and ease of use make them powerful tools in many applications.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["## Evaluating the App with Ragas\n","\n","Now we can finally do our evaluation!\n","\n","We'll start by running the queries we generated usign SDG above through our application to get context and responses."],"metadata":{"id":"nK5gyOlixWr4"}},{"cell_type":"code","source":["for test_row in dataset:\n","  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n","  test_row.eval_sample.response = response[\"response\"]\n","  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"],"metadata":{"id":"tzstmZmfxYP2","executionInfo":{"status":"ok","timestamp":1738859662061,"user_tz":360,"elapsed":74339,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":28,"outputs":[]},{"cell_type":"code","source":["dataset.to_pandas()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":790},"id":"VLXEuORVxd0l","outputId":"8cbe8010-6e2e-4699-b65e-e47c1cc2e11b","executionInfo":{"status":"ok","timestamp":1738859662062,"user_tz":360,"elapsed":34,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                           user_input  \\\n","0                 Wht did we lern about LLMs in 2024?   \n","1   How do LLMs handle the complexity of Chinese g...   \n","2       What were the key developments in AI in 2023?   \n","3       What plausible impact AI models have on jobs?   \n","4   How have advancements in model efficiency and ...   \n","5   How has the universal access to AI models evol...   \n","6   How have advancements in model efficiency and ...   \n","7   How has universal access to AI models and API ...   \n","8   What were the significant advancements in Larg...   \n","9   How has the development of Claude 3 and the ri...   \n","10  What advancements in Large Language Models (LL...   \n","11  How has Anthropic's approach to model evaluati...   \n","\n","                                   retrieved_contexts  \\\n","0   [This is Things we learned about LLMs in 2024 ...   \n","1   [So training an LLM still isn’t something a ho...   \n","2   [Law is not ethics. Is it OK to train models o...   \n","3   [Law is not ethics. Is it OK to train models o...   \n","4   [Law is not ethics. Is it OK to train models o...   \n","5   [Law is not ethics. Is it OK to train models o...   \n","6   [Law is not ethics. Is it OK to train models o...   \n","7   [For a few short months this year all three of...   \n","8   [Since then, almost every major LLM (and most ...   \n","9   [The rise of inference-scaling “reasoning” mod...   \n","10  [Training a GPT-4 beating model was a huge dea...   \n","11  [OpenAI are not the only game in town here. Go...   \n","\n","                                   reference_contexts  \\\n","0   [Code may be the best application The ethics o...   \n","1   [Based Development As a computer scientist and...   \n","2   [Simon Willison’s Weblog Subscribe Stuff we fi...   \n","3   [easy to follow. The rest of the document incl...   \n","4   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","5   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","6   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","7   [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","8   [<1-hop>\\n\\nSimon Willison’s Weblog Subscribe ...   \n","9   [<1-hop>\\n\\nI’m beginning to see the most popu...   \n","10  [<1-hop>\\n\\nVoice and live camera mode are sci...   \n","11  [<1-hop>\\n\\nI’m beginning to see the most popu...   \n","\n","                                             response  \\\n","0   In 2024, we learned several key things about L...   \n","1   LLMs handle the complexity of Chinese grammar ...   \n","2   The key developments in AI in 2023 included:\\n...   \n","3   The plausible impact of AI models on jobs incl...   \n","4   Advancements in model efficiency and pricing h...   \n","5   The evolution of universal access to AI models...   \n","6   Advancements in model efficiency and pricing h...   \n","7   In recent years, universal access to AI models...   \n","8   In 2024, significant advancements in Large Lan...   \n","9   The development of Claude 3 and the rise of in...   \n","10  In 2023, there were significant advancements i...   \n","11  Anthropic's approach to model evaluation and e...   \n","\n","                                            reference  \\\n","0   The most surprising thing we’ve learned about ...   \n","1   The grammar rules of programming languages lik...   \n","2   2023 was the breakthrough year for Large Langu...   \n","3   People have certainly lost work to AI models—a...   \n","4   Advancements in model efficiency and pricing h...   \n","5   Universal access to the best AI models was bri...   \n","6   Advancements in model efficiency and pricing h...   \n","7   Universal access to AI models experienced a br...   \n","8   In 2024, significant advancements in Large Lan...   \n","9   The development of Claude 3 and the rise of in...   \n","10  In 2023, significant advancements in Large Lan...   \n","11  Anthropic's approach to model evaluation, as h...   \n","\n","                        synthesizer_name  \n","0   single_hop_specifc_query_synthesizer  \n","1   single_hop_specifc_query_synthesizer  \n","2   single_hop_specifc_query_synthesizer  \n","3   single_hop_specifc_query_synthesizer  \n","4   multi_hop_abstract_query_synthesizer  \n","5   multi_hop_abstract_query_synthesizer  \n","6   multi_hop_abstract_query_synthesizer  \n","7   multi_hop_abstract_query_synthesizer  \n","8   multi_hop_specific_query_synthesizer  \n","9   multi_hop_specific_query_synthesizer  \n","10  multi_hop_specific_query_synthesizer  \n","11  multi_hop_specific_query_synthesizer  "],"text/html":["\n","  <div id=\"df-93f23860-9d25-44bc-a037-0bed8f417c7e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>user_input</th>\n","      <th>retrieved_contexts</th>\n","      <th>reference_contexts</th>\n","      <th>response</th>\n","      <th>reference</th>\n","      <th>synthesizer_name</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Wht did we lern about LLMs in 2024?</td>\n","      <td>[This is Things we learned about LLMs in 2024 ...</td>\n","      <td>[Code may be the best application The ethics o...</td>\n","      <td>In 2024, we learned several key things about L...</td>\n","      <td>The most surprising thing we’ve learned about ...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>How do LLMs handle the complexity of Chinese g...</td>\n","      <td>[So training an LLM still isn’t something a ho...</td>\n","      <td>[Based Development As a computer scientist and...</td>\n","      <td>LLMs handle the complexity of Chinese grammar ...</td>\n","      <td>The grammar rules of programming languages lik...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>What were the key developments in AI in 2023?</td>\n","      <td>[Law is not ethics. Is it OK to train models o...</td>\n","      <td>[Simon Willison’s Weblog Subscribe Stuff we fi...</td>\n","      <td>The key developments in AI in 2023 included:\\n...</td>\n","      <td>2023 was the breakthrough year for Large Langu...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>What plausible impact AI models have on jobs?</td>\n","      <td>[Law is not ethics. Is it OK to train models o...</td>\n","      <td>[easy to follow. The rest of the document incl...</td>\n","      <td>The plausible impact of AI models on jobs incl...</td>\n","      <td>People have certainly lost work to AI models—a...</td>\n","      <td>single_hop_specifc_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>How have advancements in model efficiency and ...</td>\n","      <td>[Law is not ethics. Is it OK to train models o...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>Advancements in model efficiency and pricing h...</td>\n","      <td>Advancements in model efficiency and pricing h...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>How has the universal access to AI models evol...</td>\n","      <td>[Law is not ethics. Is it OK to train models o...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>The evolution of universal access to AI models...</td>\n","      <td>Universal access to the best AI models was bri...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>How have advancements in model efficiency and ...</td>\n","      <td>[Law is not ethics. Is it OK to train models o...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>Advancements in model efficiency and pricing h...</td>\n","      <td>Advancements in model efficiency and pricing h...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>How has universal access to AI models and API ...</td>\n","      <td>[For a few short months this year all three of...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>In recent years, universal access to AI models...</td>\n","      <td>Universal access to AI models experienced a br...</td>\n","      <td>multi_hop_abstract_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>What were the significant advancements in Larg...</td>\n","      <td>[Since then, almost every major LLM (and most ...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nSimon Willison’s Weblog Subscribe ...</td>\n","      <td>In 2024, significant advancements in Large Lan...</td>\n","      <td>In 2024, significant advancements in Large Lan...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>How has the development of Claude 3 and the ri...</td>\n","      <td>[The rise of inference-scaling “reasoning” mod...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nI’m beginning to see the most popu...</td>\n","      <td>The development of Claude 3 and the rise of in...</td>\n","      <td>The development of Claude 3 and the rise of in...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>What advancements in Large Language Models (LL...</td>\n","      <td>[Training a GPT-4 beating model was a huge dea...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nVoice and live camera mode are sci...</td>\n","      <td>In 2023, there were significant advancements i...</td>\n","      <td>In 2023, significant advancements in Large Lan...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>How has Anthropic's approach to model evaluati...</td>\n","      <td>[OpenAI are not the only game in town here. Go...</td>\n","      <td>[&lt;1-hop&gt;\\n\\nI’m beginning to see the most popu...</td>\n","      <td>Anthropic's approach to model evaluation and e...</td>\n","      <td>Anthropic's approach to model evaluation, as h...</td>\n","      <td>multi_hop_specific_query_synthesizer</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93f23860-9d25-44bc-a037-0bed8f417c7e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-93f23860-9d25-44bc-a037-0bed8f417c7e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-93f23860-9d25-44bc-a037-0bed8f417c7e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-a884ca5b-69ab-4afb-b96d-2ed05ba52959\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a884ca5b-69ab-4afb-b96d-2ed05ba52959')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-a884ca5b-69ab-4afb-b96d-2ed05ba52959 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","summary":"{\n  \"name\": \"dataset\",\n  \"rows\": 12,\n  \"fields\": [\n    {\n      \"column\": \"user_input\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"What advancements in Large Language Models (LLMs) were highlighted in 2023, and how did they impact the capabilities of models like GPT-4?\",\n          \"How has the development of Claude 3 and the rise of inference-scaling reasoning models influenced the efficiency and capabilities of large language models in 2024?\",\n          \"Wht did we lern about LLMs in 2024?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"retrieved_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference_contexts\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"response\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"In 2023, there were significant advancements in Large Language Models (LLMs) that notably improved the capabilities of models like GPT-4. Some key highlights included:\\n\\n1. **Accessibility and Efficiency**: It became easier to build LLMs, and individuals could run these models on their own devices. For example, the author mentioned running multiple GPT-4 class models on a personal laptop, which highlights the progress in making powerful models accessible to hobbyists and researchers.\\n\\n2. **Competition and Price Reduction**: The growth in the number of available models led to a crash in LLM prices, driven by increased competition and efficiency among developers. This competition likely encouraged innovation and the rapid development of new models.\\n\\n3. **Multimodal Capabilities**: There was a notable shift toward multimodal vision, with audio and video capabilities starting to emerge. This diversification allowed LLMs to process and generate content across different media types, enhancing their functionality.\\n\\n4. **Prompt-Driven Development**: The ability to generate applications based on prompts became more commonplace, making it easier for users to create tailored applications without extensive coding knowledge.\\n\\n5. **Research and Collaboration**: Open models benefited from the contributions of a large community of researchers and hobbyists, which fostered rapid advancements and improvements over time.\\n\\n6. **Emergence of New Models**: While OpenAI's GPT-4 was the leading model for much of the year, other organizations were actively working to develop models that could compete with or surpass GPT-4, such as Google's Gemini Ultra and Mistral's models.\\n\\nThe overall impact of these advancements was a significant enhancement in the capabilities, accessibility, and affordability of LLMs, marking 2023 as a breakthrough year in the field.\",\n          \"The development of Claude 3 and the rise of inference-scaling reasoning models significantly influenced the efficiency and capabilities of large language models (LLMs) in 2024. Claude 3, launched by Anthropic, set a new standard in LLM performance, with its iterations, including Claude 3.5 Sonnet and Claude 3.6, enhancing its capabilities even further.\\n\\nInference-scaling reasoning models, such as OpenAI's o1 models, represent a key advancement in LLM design. These models incorporate a built-in reasoning process that enhances their problem-solving abilities. By utilizing \\\"reasoning tokens,\\\" these models can internally process information more effectively before delivering a final output, improving the overall quality of the results compared to traditional models that may not engage in such reasoning.\\n\\nThe competitive landscape in 2024 saw various organizations, including Google and Alibaba, releasing their own versions of inference-scaling reasoning models, indicating a broader shift in the industry towards these advanced architectures. This competition led to a decrease in LLM prices and an increase in efficiency, making powerful models more accessible.\\n\\nOverall, the combination of Claude 3's advancements and the emergence of inference-scaling reasoning models contributed to a remarkable evolution in LLM capabilities in 2024, allowing for more complex reasoning, better performance in various tasks, and a more dynamic interaction experience for users.\",\n          \"In 2024, we learned several key things about Large Language Models (LLMs):\\n\\n1. **Accessibility and Affordability**: Training LLMs is no longer just for the super-rich; while it's still not something a hobbyist can easily afford, the landscape has changed significantly, making it more accessible to a broader range of developers.\\n\\n2. **Personal Device Capability**: There has been a major breakthrough in running useful LLMs on personal devices. For example, after the release of Meta's Llama, people were able to run LLMs on their laptops.\\n\\n3. **Price Reduction**: The prices of LLMs have significantly dropped due to increased competition and efficiency in operations, making them more affordable to users.\\n\\n4. **Multimodal Models**: Multimodal capabilities have become common, with advancements in integrating vision, audio, and video functionalities into LLMs.\\n\\n5. **Prompt-driven Applications**: The generation of applications driven by prompts has become a standard practice, indicating a maturity in the technology.\\n\\n6. **Temporary Universal Access**: The period of universal access to the best models was short-lived, suggesting that the landscape is continually evolving.\\n\\n7. **Limited Progress on \\\"Agents\\\"**: The development of \\\"agents\\\"\\u2014intelligent systems that can operate independently\\u2014has not yet materialized as anticipated.\\n\\n8. **Importance of Evaluations**: Evaluations of model performance and capabilities have become increasingly important in assessing the effectiveness of LLMs.\\n\\n9. **Increased Efficiency**: There has been a notable trend towards improved efficiency and reduced energy costs in the operation of LLMs, which is a positive development for users seeking practical applications.\\n\\n10. **Emergence of New Features**: Features like voice and live camera modes have started to emerge, showcasing advancements that were once considered science fiction.\\n\\nOverall, 2024 has seen significant advancements in LLMs, emphasizing accessibility, multimodal functionalities, and a shift towards more efficient and cost-effective solutions.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"In 2023, significant advancements in Large Language Models (LLMs) were observed, marking it as a breakthrough year for AI. One of the key developments was the ability to run LLMs on personal devices, which was previously thought to require datacenter-class servers. This was exemplified by models like Qwen2.5-Coder-32B and Meta's Llama 3.3 70B, which could run on a 64GB M2 MacBook Pro. Additionally, the cost of running prompts through top-tier hosted LLMs dramatically decreased, making these models more accessible. The year also saw the emergence of models that surpassed GPT-4 in performance, with 18 organizations having models ranked higher than GPT-4-0314 on the Chatbot Arena Leaderboard. These advancements not only improved model efficiency but also expanded the capabilities of LLMs, allowing for longer input contexts and new functionalities such as video input, as seen with Google's Gemini 1.5 Pro.\",\n          \"The development of Claude 3 and the rise of inference-scaling reasoning models have significantly influenced the efficiency and capabilities of large language models in 2024. Claude 3, launched by Anthropic, became a favorite due to its enhanced capabilities, and its subsequent upgrade to Claude 3.5 Sonnet further solidified its position. This model, along with others, contributed to breaking the GPT-4 barrier, as evidenced by the fact that 18 organizations now have models ranking higher than the original GPT-4 on the Chatbot Arena Leaderboard. Additionally, the introduction of inference-scaling reasoning models, such as OpenAI's o1 and its successor o3, has opened new avenues for scaling models by allowing them to tackle harder problems through increased compute during inference rather than just during training. This has led to models that can handle more complex tasks and has driven down the cost of running prompts through top-tier hosted LLMs, making them more accessible and efficient.\",\n          \"The most surprising thing we\\u2019ve learned about LLMs this year is that they\\u2019re actually quite easy to build. Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version! What matters most is the training data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"synthesizer_name\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"single_hop_specifc_query_synthesizer\",\n          \"multi_hop_abstract_query_synthesizer\",\n          \"multi_hop_specific_query_synthesizer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":29}]},{"cell_type":"markdown","source":["Then we can convert that table into a `EvaluationDataset` which will make the process of evaluation smoother."],"metadata":{"id":"TULcXSm0AUe0"}},{"cell_type":"code","source":["from ragas import EvaluationDataset\n","\n","evaluation_dataset = EvaluationDataset.from_pandas(dataset.to_pandas())"],"metadata":{"id":"B8zQhKR7yn1d","executionInfo":{"status":"ok","timestamp":1738859662063,"user_tz":360,"elapsed":33,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":["We'll need to select a judge model - in this case we're using the same model that was used to generate our Synthetic Data."],"metadata":{"id":"qQibuzfZAbvA"}},{"cell_type":"code","source":["from ragas import evaluate\n","from ragas.llms import LangchainLLMWrapper\n","\n","evaluator_llm = LangchainLLMWrapper(ChatOpenAI(model=\"gpt-4o\"))"],"metadata":{"id":"_q3Zl7sazFYB","executionInfo":{"status":"ok","timestamp":1738859662063,"user_tz":360,"elapsed":32,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["Next up - we simply evaluate on our desired metrics!"],"metadata":{"id":"MzHuOZgBAoUU"}},{"cell_type":"code","source":["from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness, ResponseRelevancy, ContextEntityRecall, NoiseSensitivity\n","\n","result = evaluate(\n","    dataset=evaluation_dataset,\n","    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n","    llm=evaluator_llm\n",")\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":712,"referenced_widgets":["f22d837877fe44178f064641c873d053","78719c3074564b609574a67f61a3d771","a3b07ef88ed24d37b0e0601a0f81408a","8c31e1565f204652950556a6916dea4d","01eddca9b41e46f2b790788fb50d1a08","cfff5091b6fe41a38ec7ee22acfc71e0","40ff01bb41ad4d81a3d579dcbc2c923b","ac19798d07c7444b8e2e8d2edb45f3cd","7a6c05e7d7d74f369f79771e4ff0b741","a661d000cbe743378d0c813b4cbe7d3f","6e649fb90af940f0bdc255e1f5fa95a3"]},"id":"M6mw2AeKziF1","outputId":"3cdd4060-c5ab-42b1-d5a0-f814d34a745d","executionInfo":{"status":"ok","timestamp":1738860251848,"user_tz":360,"elapsed":589817,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f22d837877fe44178f064641c873d053"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["ERROR:ragas.executor:Exception raised in Job[13]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29876, Requested 2622. Please try again in 4.996s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[1]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[5]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[7]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[11]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[16]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[17]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[19]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[22]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[25]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[30]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29111, Requested 2349. Please try again in 2.92s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[29]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[42]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29343, Requested 2432. Please try again in 3.55s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[31]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[36]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 28508, Requested 2338. Please try again in 1.692s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[34]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[35]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[37]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[41]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[43]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[46]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[47]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[48]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[49]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[52]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[53]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[54]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[55]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[59]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[61]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[62]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[65]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[71]: TimeoutError()\n"]},{"output_type":"execute_result","data":{"text/plain":["{'context_recall': 0.6778, 'faithfulness': 0.3913, 'factual_correctness': 0.4200, 'answer_relevancy': 0.9567, 'context_entity_recall': 0.3786, 'noise_sensitivity_relevant': 0.2727}"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["## Making Adjustments and Re-Evaluating\n","\n","Now that we've got our baseline - let's make a change and see how the model improves or doesn't improve!\n","\n","> NOTE: This will be using Cohere's Rerank model - please be sure to sign-up [here](https://cohere.com/rerank) for an API key!\n","\n","\n","API Key : https://dashboard.cohere.com/api-keys"],"metadata":{"id":"sZxxr2NqAyBp"}},{"cell_type":"code","source":["os.environ[\"COHERE_API_KEY\"] = getpass(\"Please enter your Cohere API key!\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JMpf7nFDBH-K","outputId":"412cdcff-5532-4b01-917d-648b896dbdfe","executionInfo":{"status":"ok","timestamp":1738860324416,"user_tz":360,"elapsed":2263,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":33,"outputs":[{"name":"stdout","output_type":"stream","text":["Please enter your Cohere API key!··········\n"]}]},{"cell_type":"code","source":["!pip install -qU cohere langchain_cohere"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zMwNl2M5BYWg","outputId":"1fa4843f-96e7-4089-c86e-79ff6f0875fd","executionInfo":{"status":"ok","timestamp":1738860332821,"user_tz":360,"elapsed":5973,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/252.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m215.0/252.9 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.9/252.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/3.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/3.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m74.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["retriever = vector_store.as_retriever(search_kwargs={\"k\": 20})"],"metadata":{"id":"3Oa5r78dA4K9","executionInfo":{"status":"ok","timestamp":1738860332821,"user_tz":360,"elapsed":6,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n","from langchain_cohere import CohereRerank\n","\n","def retrieve_adjusted(state):\n","  compressor = CohereRerank(model=\"rerank-english-v3.0\")\n","  compression_retriever = ContextualCompressionRetriever(\n","    base_compressor=compressor, base_retriever=retriever, search_kwargs={\"k\": 5}\n","  )\n","  retrieved_docs = compression_retriever.invoke(state[\"question\"])\n","  return {\"context\" : retrieved_docs}"],"metadata":{"id":"B3d3B3OEBCCc","executionInfo":{"status":"ok","timestamp":1738860338414,"user_tz":360,"elapsed":5598,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["class State(TypedDict):\n","  question: str\n","  context: List[Document]\n","  response: str\n","\n","graph_builder = StateGraph(State).add_sequence([retrieve_adjusted, generate])\n","graph_builder.add_edge(START, \"retrieve_adjusted\")\n","graph = graph_builder.compile()"],"metadata":{"id":"4XZKorBaB4BW","executionInfo":{"status":"ok","timestamp":1738860338415,"user_tz":360,"elapsed":4,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["response = graph.invoke({\"question\" : \"How are LLM agents useful?\"})\n","response[\"response\"]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":107},"id":"s7doJbZJB_19","outputId":"b4e94316-24ed-4376-ba0e-025ff8f39bd7","executionInfo":{"status":"ok","timestamp":1738860341682,"user_tz":360,"elapsed":3271,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["\"LLM agents are perceived as potentially useful in various applications, particularly in coding, where they have shown a high level of capability. They can assist in writing code, which is less complex than natural language grammar, making them effective tools in that domain. Additionally, there is excitement surrounding the concept of AI agents that can act on users' behalf, although there is skepticism about their reliability due to concerns over gullibility and the inability to distinguish truth from fiction. Critics emphasize the importance of discussing the ethical implications and challenges associated with LLMs, urging caution and responsible use of these technologies.\""],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["for test_row in dataset:\n","  response = graph.invoke({\"question\" : test_row.eval_sample.user_input})\n","  test_row.eval_sample.response = response[\"response\"]\n","  test_row.eval_sample.retrieved_contexts = [context.page_content for context in response[\"context\"]]"],"metadata":{"id":"siBFKs-gCDdQ","executionInfo":{"status":"ok","timestamp":1738860417652,"user_tz":360,"elapsed":75973,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["result = evaluate(\n","    dataset=evaluation_dataset,\n","    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness(), ResponseRelevancy(), ContextEntityRecall(), NoiseSensitivity()],\n","    llm=evaluator_llm\n",")\n","result"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":730,"referenced_widgets":["c13e5b8733e84c4bb9d3b3863dcfd2e5","b00b3083c45a46d09d0a94ff18111028","1cf0cbb87244493bbe7bc15b8b6b9a7e","a0ba007a755a4ef8a766074ffef6b9fa","3d7e5e39830f4542af08458bb6f24693","0ade375a9cdf43a0a092042917ce1130","5969d04d247c4ae58b58ef13381aa312","f35c92e09eb543d9aa6f933d00092d8b","35a7936a421c4165b0bfdfbbe809d498","0811a7e3d96a43b4bba083483f8fa29a","597b05f5120d46d1a9c213793a1d2767"]},"id":"5jXHvoIDCeKI","outputId":"1485afa9-3f61-4cea-b4b7-1dc75bd33dd5","executionInfo":{"status":"ok","timestamp":1738861036138,"user_tz":360,"elapsed":618507,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":["Evaluating:   0%|          | 0/72 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c13e5b8733e84c4bb9d3b3863dcfd2e5"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["ERROR:ragas.executor:Exception raised in Job[22]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29400, Requested 1837. Please try again in 2.474s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[2]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29795, Requested 1587. Please try again in 2.764s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[1]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[5]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[7]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[10]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[13]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[16]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[17]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[19]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[24]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[25]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[26]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 28982, Requested 1699. Please try again in 1.362s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[29]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[30]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29012, Requested 2349. Please try again in 2.722s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[31]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[44]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 28930, Requested 1869. Please try again in 1.598s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[43]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29202, Requested 1923. Please try again in 2.25s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[35]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[36]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[37]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[41]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[42]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[48]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29675, Requested 2368. Please try again in 4.085s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[47]: RateLimitError(Error code: 429 - {'error': {'message': 'Rate limit reached for gpt-4o in organization org-1a7uFAatkr7hjd3rqKa2Vpxy on tokens per min (TPM): Limit 30000, Used 29806, Requested 1923. Please try again in 3.458s. Visit https://platform.openai.com/account/rate-limits to learn more.', 'type': 'tokens', 'param': None, 'code': 'rate_limit_exceeded'}})\n","ERROR:ragas.executor:Exception raised in Job[49]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[53]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[54]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[55]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[56]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[59]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[60]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[61]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[65]: TimeoutError()\n","ERROR:ragas.executor:Exception raised in Job[71]: TimeoutError()\n"]},{"output_type":"execute_result","data":{"text/plain":["{'context_recall': 0.6800, 'faithfulness': 0.4783, 'factual_correctness': 0.4450, 'answer_relevancy': 0.9580, 'context_entity_recall': 0.4098, 'noise_sensitivity_relevant': 0.1667}"]},"metadata":{},"execution_count":40}]},{"cell_type":"code","source":[],"metadata":{"id":"EuvTx0z4JwVn","executionInfo":{"status":"ok","timestamp":1738861036138,"user_tz":360,"elapsed":21,"user":{"displayName":"Duc Vu","userId":"11871278749853168900"}}},"execution_count":40,"outputs":[]}]}